{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOYXmkDNtSnlWIoLxxN2TqI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDyWEisDm6Es","executionInfo":{"status":"ok","timestamp":1768523521042,"user_tz":180,"elapsed":3318,"user":{"displayName":"Arthur Santos","userId":"03203688616351214794"}},"outputId":"729b6db5-f35c-4613-f376-79304f9d1f27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import os\n","import pandas as pd\n","import joblib\n","from datetime import datetime\n","\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["PASTA_BASE = \"/content/drive\""],"metadata":{"id":"K-AKFlpOqW5i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PASTA_BASE = \"/content/drive\"\n","ARQUIVO_TREINO = os.path.join(PASTA_BASE, \"arquivo.csv\")\n","COLUNA_TEXTO = \"coluna_x\"\n","COLUNA_LABEL = \"coluna_y\" # 1 = X, 0 = não X\n","\n","# Dados para classificação em lote\n","EXTENSOES_VALIDAS = (\".csv\", \".xlsx\")\n","\n","\n","# Limiares para revisão humana\n","LIMIAR_CONFIANTE = 0.90  # Ajustado de 0.80\n","LIMIAR_DUVIDOSO = 0.40   # Ajustado de 0.50\n","\n","\n","# Nomes dos artefatos\n","ARQ_VECTORIZER = os.path.join(PASTA_BASE, \"vectorizer.joblib\")\n","ARQ_MODEL = os.path.join(PASTA_BASE, \"model.joblib\")\n","\n","print(\"Todas as variáveis de configuração foram definidas em uma única célula.\")"],"metadata":{"id":"AzaFGLaum8a1","executionInfo":{"status":"ok","timestamp":1768523521381,"user_tz":180,"elapsed":311,"user":{"displayName":"Arthur Santos","userId":"03203688616351214794"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0359b8f2-065a-4e05-de9f-eaeba303ce55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Todas as variáveis de configuração foram definidas em uma única célula.\n"]}]},{"cell_type":"code","source":["def treinar_e_salvar_modelo():\n","    training_dfs = []\n","\n","    # Iterar sobre todos os arquivos na PASTA_BASE\n","    for f in os.listdir(PASTA_BASE):\n","        caminho_arquivo = os.path.join(PASTA_BASE, f)\n","        nome_base, extensao = os.path.splitext(f)\n","\n","        # Verificar se é um arquivo válido para treinamento\n","        # Removida a exclusão explícita de ARQUIVO_TREINO para que ele seja incluído no loop\n","        if (os.path.isfile(caminho_arquivo) and\n","            extensao.lower() in EXTENSOES_VALIDAS and\n","            \"_classificado\" not in nome_base):\n","\n","            print(f\"Tentando carregar arquivo para treino: {caminho_arquivo}\")\n","            temp_df = None\n","            try:\n","                if extensao.lower() == \".csv\":\n","                    try:\n","                        temp_df = pd.read_csv(caminho_arquivo, sep=';')\n","                    except Exception:\n","                        temp_df = pd.read_csv(caminho_arquivo, sep=',')\n","                elif extensao.lower() == \".xlsx\":\n","                    temp_df = pd.read_excel(caminho_arquivo)\n","\n","                if temp_df is not None:\n","                    # Verificar se as colunas necessárias existem\n","                    if COLUNA_TEXTO not in temp_df.columns or COLUNA_LABEL not in temp_df.columns:\n","                        print(f\"⚠️ Aviso: Arquivo '{f}' não contém as colunas '{COLUNA_TEXTO}' e/ou '{COLUNA_LABEL}'. Pulando este arquivo.\")\n","                        continue\n","\n","                    training_dfs.append(temp_df)\n","\n","            except Exception as e:\n","                print(f\"❌ Erro ao carregar o arquivo '{f}': {e}. Pulando este arquivo.\")\n","                continue\n","\n","    # Combinar todos os DataFrames carregados\n","    if not training_dfs:\n","        print(\"❌ Erro: Nenhum arquivo de treino válido encontrado ou carregado. Não é possível treinar o modelo.\")\n","        return\n","\n","    df_train = pd.concat(training_dfs, ignore_index=True)\n","\n","    if df_train.empty:\n","        print(\"❌ Erro: DataFrame de treino resultante está vazio. Não é possível treinar o modelo.\")\n","        return\n","\n","    df_train[COLUNA_TEXTO] = df_train[COLUNA_TEXTO].fillna(\"\")\n","\n","    # Processar a coluna de rótulo para considerar 'x' como 1 e outros como 0\n","    df_train[COLUNA_LABEL] = df_train[COLUNA_LABEL].astype(str).str.strip().str.lower().apply(\n","        lambda val: 1 if val == \"x\" else 0\n","    )\n","    df_train[COLUNA_LABEL] = df_train[COLUNA_LABEL].astype(int)\n","\n","    # Vectorizer\n","    vectorizer = TfidfVectorizer(\n","        lowercase=True,\n","        ngram_range=(1, 2),\n","        min_df=2,\n","        max_df=0.95\n","    )\n","\n","    X_train = vectorizer.fit_transform(df_train[COLUNA_TEXTO])\n","    y_train = df_train[COLUNA_LABEL]\n","\n","    # --- Adicionado para depuração: verificar a distribuição das classes após o processamento ---\n","    print(\"Distribuição das classes na coluna '{}' após processamento:\".format(COLUNA_LABEL))\n","    print(y_train.value_counts())\n","    # --------------------------------------------------------------------------------------\n","\n","    # Modelo\n","    model = LogisticRegression(max_iter=1000)\n","    model.fit(X_train, y_train)\n","\n","    # Salvar artefatos\n","    joblib.dump(vectorizer, ARQ_VECTORIZER)\n","    joblib.dump(model, ARQ_MODEL)\n","\n","    print(\"✔ Modelo treinado e salvo\")\n","    print(ARQ_VECTORIZER)\n","    print(ARQ_MODEL)"],"metadata":{"id":"WrrHt09xnCyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25c5b6b5","executionInfo":{"status":"ok","timestamp":1768523533460,"user_tz":180,"elapsed":12076,"user":{"displayName":"Arthur Santos","userId":"03203688616351214794"}},"outputId":"e13b883a-2fa4-4560-c347-20d4ce665541"},"source":["treinar_e_salvar_modelo()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tentando carregar arquivo para treino: /content/drive/MyDrive/teste_marcacao/revisar/dados_treino.csv\n","Distribuição das classes na coluna 'excluir' após processamento:\n","excluir\n","1    711\n","0    371\n","Name: count, dtype: int64\n","✔ Modelo treinado e salvo\n","/content/drive/MyDrive/teste_marcacao/revisar/vectorizer.joblib\n","/content/drive/MyDrive/teste_marcacao/revisar/model.joblib\n"]}]},{"cell_type":"code","source":["def carregar_modelo():\n","    if not os.path.exists(ARQ_VECTORIZER) or not os.path.exists(ARQ_MODEL):\n","        raise FileNotFoundError(\"Vectorizer/Model não encontrados. Rode o BLOCO 3 primeiro.\")\n","\n","    vectorizer = joblib.load(ARQ_VECTORIZER)\n","    model = joblib.load(ARQ_MODEL)\n","    return vectorizer, model"],"metadata":{"id":"5cl_gL_UnD6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def classificar_arquivo(caminho_arquivo, vectorizer, model):\n","    nome_base, extensao = os.path.splitext(os.path.basename(caminho_arquivo))\n","\n","    # Carregar dados\n","    if extensao == \".csv\":\n","        try:\n","            df = pd.read_csv(caminho_arquivo, sep=';')\n","        except Exception as e:\n","            print(f\"Erro ao ler CSV com ponto e vírgula: {e}. Tentando com vírgula...\")\n","            df = pd.read_csv(caminho_arquivo, sep=',')\n","    else:\n","        df = pd.read_excel(caminho_arquivo)\n","\n","    # Verificar se a COLUNA_TEXTO existe\n","    if COLUNA_TEXTO not in df.columns:\n","        print(f\"Erro: O arquivo '{caminho_arquivo}' não possui a coluna '{COLUNA_TEXTO}'. Colunas disponíveis: {df.columns.tolist()}\")\n","        raise KeyError(f\"Coluna '{COLUNA_TEXTO}' não encontrada no arquivo '{caminho_arquivo}'.\")\n","\n","    df[COLUNA_TEXTO] = df[COLUNA_TEXTO].fillna(\"\")\n","\n","    # Remover caracteres ilegais para XML/Excel\n","    illegal_char_re = re.compile(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f]')\n","    df[COLUNA_TEXTO] = df[COLUNA_TEXTO].apply(lambda x: illegal_char_re.sub('', x) if isinstance(x, str) else x)\n","\n","    # Vetorização\n","    X = vectorizer.transform(df[COLUNA_TEXTO])\n","\n","    # Predições\n","    probas = model.predict_proba(X)[:, 1]\n","    preds = model.predict(X)\n","\n","    df[\"prob_X\"] = probas\n","    df[\"marcacao_X\"] = pd.Series(preds).map({1: \"x\", 0: \"\"})\n","\n","    # Revisão humana - Lógica invertida para CONFIANTE e DESCARTADO\n","    df[\"status_revisao\"] = df[\"prob_X\"].apply(\n","        lambda p:\n","            (\n","                \"DESCARTADO\" if p >= LIMIAR_CONFIANTE else  # Se alta probabilidade de ser 'X' (excluir), marca como DESCARTADO\n","                \"REVISAR\" if p >= LIMIAR_DUVIDOSO else      # Se probabilidade intermediária, marca como REVISAR\n","                \"CONFIANTE\"                                 # Se baixa probabilidade de ser 'X' (não excluir), marca como CONFIANTE\n","            )\n","    )\n","\n","    # Versionamento\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","    # Cria a pasta 'resultados' se não existir\n","    pasta_resultados = os.path.join(PASTA_BASE, \"resultados\")\n","    os.makedirs(pasta_resultados, exist_ok=True)\n","\n","    saida = os.path.join(\n","        pasta_resultados,\n","        f\"{nome_base}_classificado_{timestamp}.xlsx\"\n","    )\n","\n","    df.to_excel(saida, index=False)\n","    return saida"],"metadata":{"id":"s8ipxlOanFEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def classificar_pasta():\n","    vectorizer, model = carregar_modelo()\n","\n","    arquivos = [\n","        f for f in os.listdir(PASTA_BASE)\n","        if f.endswith(EXTENSOES_VALIDAS)\n","        and not f.endswith(\"_classificado.xlsx\")\n","        and os.path.join(PASTA_BASE, f) != ARQUIVO_TREINO  # Excluir o arquivo de treino\n","    ]\n","\n","    if not arquivos:\n","        print(\"Nenhum arquivo para classificar.\")\n","        return\n","\n","    saidas = []\n","    for f in arquivos:\n","        caminho = os.path.join(PASTA_BASE, f)\n","        print(f\"Tentando classificar arquivo: {caminho}\") # Adicionado para depuração\n","        try:\n","            saida = classificar_arquivo(caminho, vectorizer, model)\n","            saidas.append(saida)\n","        except (KeyError, pd.errors.ParserError) as e:\n","            print(f\"❌ Erro ao classificar o arquivo {caminho}: {e}. Pulando este arquivo.\")\n","        except Exception as e:\n","            print(f\"❌ Ocorreu um erro inesperado ao classificar o arquivo {caminho}: {e}. Pulando este arquivo.\")\n","\n","    print(\"✔ Classificação em lote concluída\")\n","    for s in saidas:\n","        print(\"Gerado:\", s)"],"metadata":{"id":"zgIwXMXKotmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7d79f08b","executionInfo":{"status":"ok","timestamp":1768523534685,"user_tz":180,"elapsed":1220,"user":{"displayName":"Arthur Santos","userId":"03203688616351214794"}},"outputId":"9a64ac01-0fdb-4d35-b38f-eafb6d3d0237"},"source":["import os\n","print(f\"Conteúdo da pasta '{PASTA_BASE}':\")\n","conteudo_pasta = os.listdir(PASTA_BASE)\n","if not conteudo_pasta:\n","    print(\"  (Vazio)\")\n","else:\n","    for item in conteudo_pasta:\n","        print(f\"  - {item}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conteúdo da pasta '/content/drive/MyDrive/teste_marcacao/revisar/':\n","  - dados_treino.csv\n","  - conteudo_lote_17_unificado_classificado_20260113_232900.xlsx\n","  - conteudo_lote_17_unificado (1)_classificado_20260113_232904.xlsx\n","  - conteudo_lote_18_unificado_classificado_20260113_232907.xlsx\n","  - conteudo_lote_21_unificado_classificado_20260113_232910.xlsx\n","  - conteudo_lote_20_unificado_classificado_20260113_232912.xlsx\n","  - conteudo_lote_19_unificado_classificado_20260113_232914.xlsx\n","  - conteudo_lote_15_unificado_classificado_20260113_232917.xlsx\n","  - conteudo_lote_16_unificado_classificado_20260113_232921.xlsx\n","  - conteudo_lote_0406_unificado_classificado_20260113_232928.xlsx\n","  - conteudo_lote_24_unificado_classificado_20260113_232933.xlsx\n","  - conteudo_lote_25_unificado_classificado_20260113_232936.xlsx\n","  - conteudo_lote_0710_unificado_classificado_20260113_232949.xlsx\n","  - conteudo_lote_1114_unificado_classificado_20260113_233006.xlsx\n","  - conteudo_lote_22_unificado_classificado_20260113_233014.xlsx\n","  - conteudo_lote_23_unificado_classificado_20260113_233018.xlsx\n","  - vectorizer.joblib\n","  - model.joblib\n","  - resultados\n"]}]},{"cell_type":"code","source":["classificar_pasta()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSMH7m7SsoZo","executionInfo":{"status":"ok","timestamp":1768523623501,"user_tz":180,"elapsed":88821,"user":{"displayName":"Arthur Santos","userId":"03203688616351214794"}},"outputId":"25dbde7e-a176-4154-fd48-a41ed8b373c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_17_unificado_classificado_20260113_232900.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_17_unificado (1)_classificado_20260113_232904.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_18_unificado_classificado_20260113_232907.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_21_unificado_classificado_20260113_232910.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_20_unificado_classificado_20260113_232912.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_19_unificado_classificado_20260113_232914.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_15_unificado_classificado_20260113_232917.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_16_unificado_classificado_20260113_232921.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_0406_unificado_classificado_20260113_232928.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_24_unificado_classificado_20260113_232933.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_25_unificado_classificado_20260113_232936.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_0710_unificado_classificado_20260113_232949.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_1114_unificado_classificado_20260113_233006.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_22_unificado_classificado_20260113_233014.xlsx\n","Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_23_unificado_classificado_20260113_233018.xlsx\n","✔ Classificação em lote concluída\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_17_unificado_classificado_20260113_232900_classificado_20260116_003220.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_17_unificado (1)_classificado_20260113_232904_classificado_20260116_003225.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_18_unificado_classificado_20260113_232907_classificado_20260116_003230.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_21_unificado_classificado_20260113_232910_classificado_20260116_003232.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_20_unificado_classificado_20260113_232912_classificado_20260116_003234.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_19_unificado_classificado_20260113_232914_classificado_20260116_003236.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_15_unificado_classificado_20260113_232917_classificado_20260116_003240.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_16_unificado_classificado_20260113_232921_classificado_20260116_003245.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_0406_unificado_classificado_20260113_232928_classificado_20260116_003251.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_24_unificado_classificado_20260113_232933_classificado_20260116_003258.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_25_unificado_classificado_20260113_232936_classificado_20260116_003301.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_0710_unificado_classificado_20260113_232949_classificado_20260116_003314.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_1114_unificado_classificado_20260113_233006_classificado_20260116_003332.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_22_unificado_classificado_20260113_233014_classificado_20260116_003342.xlsx\n","Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_23_unificado_classificado_20260113_233018_classificado_20260116_003346.xlsx\n"]}]}]}